{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"},{"sourceId":11212096,"sourceType":"datasetVersion","datasetId":7001095}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ARC-AGI Without Pretraining - Official Competition Template Version\nThis file interfaces between the kaggle competition website and the rest of the solution code, which is included in the input files.\n\nThe main differences between this notebook and the method in the ARC-AGI Without Pretraining blog post aim to parallelize the solving of many puzzles at once using all the CPUs and GPUs that are offered in this competition. In the blog post, we solved puzzles in series, vastly underutilized one RTX 4070 GPU, and blew past the time budget. Instead, what we do in this notebook is:\n- We run 2 steps of every puzzle to determine how much memory each puzzle uses.\n- We run 10 steps of every puzzle at optimal puzzle parallelization under memory constraint to determine how much time per step we need to solve the puzzles in bulk.\n- We run as many steps as we can at optimal puzzle parallelization under memory constraint to fit a 12 hour budget.\n- We have changed layers.direction_share() to make it run faster, and got something like a 5-10% speedup.\n\nIf the dataset size is 120 puzzles, we should expect this to get ~2300 steps in per puzzle.","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport json\nimport importlib\nimport multiprocessing\nfrom multiprocessing import Pool\n\nimport numpy as np\nimport torch\n\nsys.path.append('/kaggle/input/compressarc')\n\n# This little block of code does \"import preprocessing\" but avoids a name collision with another module\nmodule_path = \"/kaggle/input/compressarc/preprocessing.py\"\nmodule_name = \"preprocessing\"\nspec = importlib.util.spec_from_file_location(module_name, module_path)\npreprocessing = importlib.util.module_from_spec(spec)\nsys.modules[module_name] = preprocessing\nspec.loader.exec_module(preprocessing)\nimport train\nimport arc_compressor\nimport initializers\nimport multitensor_systems\nimport layers\nimport solution_selection\nimport visualization\nimport solve_task","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T04:05:19.678216Z","iopub.execute_input":"2025-03-30T04:05:19.678502Z","iopub.status.idle":"2025-03-30T04:05:23.186962Z","shell.execute_reply.started":"2025-03-30T04:05:19.67848Z","shell.execute_reply":"2025-03-30T04:05:23.18631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Getting all the task names, setting defaults and constants","metadata":{}},{"cell_type":"code","source":"multiprocessing.set_start_method('spawn', force=True)\ntorch.set_default_dtype(torch.float32)\ntorch.set_default_device('cuda')\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cuda.matmul.allow_tf32 = True\n\nif __name__ == '__main__':\n\n    start_time = time.time()\n    end_time = start_time + 12*3600 - 300\n\n    n_cpus = multiprocessing.cpu_count()\n    n_gpus = torch.cuda.device_count()\n\n    # Find all the puzzle names\n    split = \"test\"\n    with open(f'../input/arc-prize-2025/arc-agi_{split}_challenges.json', 'r') as f:\n        problems = json.load(f)\n    task_names = list(problems.keys())\n    del problems\n    n_tasks = len(task_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T04:05:23.187842Z","iopub.execute_input":"2025-03-30T04:05:23.188172Z","iopub.status.idle":"2025-03-30T04:05:23.339212Z","shell.execute_reply.started":"2025-03-30T04:05:23.188145Z","shell.execute_reply":"2025-03-30T04:05:23.338574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Function that can spawn processes and schedule them on GPUs to take up each GPUs quota","metadata":{}},{"cell_type":"code","source":"def parallelize_runs(gpu_quotas, task_usages, n_iterations, verbose=False):\n    gpu_quotas = gpu_quotas[:]\n    # Schedule the tasks greedily to max out memory usage\n    t = time.time()\n    tasks_started = [False for i in range(n_tasks)]\n    tasks_finished = [False for i in range(n_tasks)]\n    processes = [None for i in range(n_tasks)]\n    process_gpu_ids = [None for i in range(n_tasks)]\n    with multiprocessing.Manager() as manager:\n        memory_dict = manager.dict()\n        solutions_dict = manager.dict()\n        error_queue = manager.Queue()\n        while not all(tasks_finished):\n            if not error_queue.empty():\n                raise ValueError(error_queue.get())\n            for i in range(n_tasks):\n                if tasks_started[i] and not tasks_finished[i]:\n                    processes[i].join(timeout=0)\n                    if not processes[i].is_alive():\n                        tasks_finished[i] = True\n                        gpu_quotas[process_gpu_ids[i]] += task_usages[i]\n                        if verbose:\n                            print(task_names[i], 'finished on gpu', process_gpu_ids[i],\n                                  'New quota is', gpu_quotas[process_gpu_ids[i]])\n            for gpu_id in range(n_gpus):\n                for i in range(n_tasks):\n                    enough_quota = gpu_quotas[gpu_id] > task_usages[i]\n                    enough_cpus = sum(map(int, tasks_started)) - sum(map(int, tasks_finished)) < n_cpus\n                    if not tasks_started[i] and enough_quota and enough_cpus:\n                        gpu_quotas[gpu_id] -= task_usages[i]\n                        args = (task_names[i], split, end_time, n_iterations, gpu_id, memory_dict, solutions_dict, error_queue)\n                        p = multiprocessing.Process(target=solve_task.solve_task, args=args)\n                        p.start()\n                        processes[i] = p\n                        tasks_started[i] = True\n                        process_gpu_ids[i] = gpu_id\n                        if verbose:\n                            print(task_names[i], 'started on gpu', process_gpu_ids[i],\n                                  'New quota is', gpu_quotas[process_gpu_ids[i]])\n            time.sleep(1)\n        if not error_queue.empty():\n            raise ValueError(error_queue.get())\n        memory_dict = dict(memory_dict)\n        solutions_dict = dict(solutions_dict)\n    time_taken = time.time() - t\n    if verbose:\n        print('All jobs finished in', time_taken, 'seconds.')\n    return memory_dict, solutions_dict, time_taken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T04:05:23.340363Z","iopub.execute_input":"2025-03-30T04:05:23.340573Z","iopub.status.idle":"2025-03-30T04:05:23.349348Z","shell.execute_reply.started":"2025-03-30T04:05:23.340555Z","shell.execute_reply":"2025-03-30T04:05:23.348749Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Measuring the amount of memory used for every task","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    gpu_memory_quotas = [torch.cuda.mem_get_info(i)[0] for i in range(n_gpus)]\n\n    gpu_task_quotas = [int(gpu_memory_quota // (4 * 1024**3)) for gpu_memory_quota in gpu_memory_quotas]\n    task_usages = [1 for i in range(n_tasks)]\n    memory_dict, _, _ = parallelize_runs(gpu_task_quotas, task_usages, 2, verbose=False)\n    \n    # Sort the tasks by decreasing memory usage\n    tasks = sorted(memory_dict.items(), key=lambda x: x[1], reverse=True)\n    task_names, task_memory_usages = zip(*tasks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T04:05:23.350251Z","iopub.execute_input":"2025-03-30T04:05:23.350448Z","iopub.status.idle":"2025-03-30T04:07:09.252642Z","shell.execute_reply.started":"2025-03-30T04:05:23.350432Z","shell.execute_reply":"2025-03-30T04:07:09.251912Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Computing the time taken, while saturating memory","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    test_steps = 20\n    safe_gpu_memory_quotas = [memory_quota - 6 * 1024**3 for memory_quota in gpu_memory_quotas]\n    _, _, time_taken = parallelize_runs(safe_gpu_memory_quotas, task_memory_usages, test_steps, verbose=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T04:07:09.253285Z","iopub.execute_input":"2025-03-30T04:07:09.253488Z","iopub.status.idle":"2025-03-30T04:10:47.618982Z","shell.execute_reply.started":"2025-03-30T04:07:09.253471Z","shell.execute_reply":"2025-03-30T04:10:47.618304Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Computing the solution for every task, while saturating memory and time","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    time_per_step = time_taken / test_steps\n    time_left = end_time - time.time()\n    n_steps = int(time_left // time_per_step)\n    _, solutions_dict, time_taken = parallelize_runs(safe_gpu_memory_quotas, task_memory_usages, n_steps, verbose=True)\n    \n    # Format the solutions and put into submission file\n    with open('submission.json', 'w') as f:\n        json.dump(solutions_dict, f, indent=4)\n        \n    print(n_tasks, 'tasks solved.')\n    print(n_steps, 'steps taken.')\n    print(time_taken, 'seconds taken.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T04:10:47.619663Z","iopub.execute_input":"2025-03-30T04:10:47.619864Z"}},"outputs":[],"execution_count":null}]}